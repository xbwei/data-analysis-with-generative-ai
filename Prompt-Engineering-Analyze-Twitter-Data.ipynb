{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119a978c-794a-42a7-8926-cda6871c8613",
   "metadata": {},
   "source": [
    "# Prompt Engineering: Use OpenAI to Analyze Twitter Data \n",
    "This is a simple tutorial teaching prompt engineering basics and analyzing Twitter data with OpenAI large language models (LLM).\n",
    "Please purchase an [OpenAI API](https://openai.com/index/openai-api/) and store it in a safe place. This tutorial uses [AWS Secretes Manager](https://aws.amazon.com/secrets-manager/) to store the API keys.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15700978-787e-407e-a940-c977a71b3044",
   "metadata": {},
   "source": [
    "## Large Language Model Basics\n",
    "LLM repeatable predicts the next world using supervised learning. To predict the following sentence: \n",
    "\n",
    "`Learning data science in the cloud with AI`\n",
    "\n",
    "A model needs to learn to predict the following steps:\n",
    "\n",
    "|Input|Output|\n",
    "|:---|---|\n",
    "|Learning data science |in |\n",
    "|Learning data science in |the | \n",
    "|Learning data science in the |cloud |\n",
    "|Learning data science in the cloud |with |\n",
    "|Learning data science in the cloud with |AI|\n",
    "\n",
    "To train an LLM model:\n",
    "1. Training a base LLM model on a large amount of training data to predict the next word \n",
    "2. Fine-tune on examples where outputs follow instructions in the input \n",
    "3. Human rates quality of different LLM outputs \n",
    "4. Tune LLM to generate outputs with higher rates using RLHF (Reinforcement learning from human feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726290-4f69-4f9f-94d4-18b9c8f26f14",
   "metadata": {},
   "source": [
    "## Set up OpenAI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9019645-db86-4235-93e7-cbd52e770afc",
   "metadata": {},
   "source": [
    "Load the API keys with AWS Secrets Manage Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f6d31-1f82-47e5-9fa4-de3da8aa068a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92790e72-aea1-4acc-b98d-a6782550777c",
   "metadata": {},
   "source": [
    "## Install Python libraries.\n",
    "\n",
    "- pymongo: manage the MongoDB database\n",
    "- openai: call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4f923-3b7c-4bd2-945a-1fbda250e8df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ab01b-f2f1-4c10-8936-7dca341af6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276093f1-824b-4793-bb59-dc30c7d84fb4",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and define a `openai_help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126647a-fbda-42c3-bebb-d689802c6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "def openai_help(messages, model=model, temperature =temperature ):\n",
    "    messages = messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bc14c-2609-4c3e-aa5d-762cd3d06ac0",
   "metadata": {},
   "source": [
    "Temperature: \n",
    "- Low temperature: always choose the most likely response, reliable, predictable responses  \n",
    "- High temperature: diverse responses, more creative responses\n",
    "\n",
    "Tokens and Models: \n",
    "- LLM predicts tokens, which are commonly occurring sequences of characters. \n",
    "- One token is about four characters in English, and 100 tokens are roughly 75 words. Check [token estimate](https://platform.openai.com/tokenizer).\n",
    "- Different models can process various amounts of tokens at different performance levels and costs. Check [OpenAI models](https://platform.openai.com/docs/models) for more details.\n",
    "\n",
    "Roles:\n",
    "- system: specify the overall tone or behavior of the assistant \n",
    "- user: instruction given to the LLM\n",
    "- assistant: LLM responded content, we also can provide content in few-shot promoting or histories of conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef378-e825-40ca-a565-371ba96268a1",
   "metadata": {},
   "source": [
    "A simple example using [gtp-4o](https://platform.openai.com/docs/models/gpt-4o) and temperature 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b746d9-f11f-4f46-96f5-64dd40f6dc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of USA\"}]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcbc19-1ea0-456a-ba84-8f76ef87ba30",
   "metadata": {},
   "source": [
    "Add a system message asking LLM to act as a high school teacher with different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608f8d0-fefb-41a7-8713-1287b3cd7047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"use tone as a high school teacher\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of USA\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages, temperature = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887fc65-5f97-4530-b81b-f158ea2af413",
   "metadata": {},
   "source": [
    "Add assistant messages to teach LLM what `##` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37e101-f820-4ba7-969c-ce05b53aafe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 1##1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 11\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2##2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 22\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 3##3\"},\n",
    "    ]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addef986-2e0c-4849-bc7a-48b102fbf2fe",
   "metadata": {},
   "source": [
    "## Prompt Engineering Principles \n",
    "- Use delimiters to separate different parts of a prompt to provide clear instructions and prevent prompt injections.\n",
    "- Structure outputs in JSON documents or other formats to use the outputs in subsequent steps \n",
    "- Few-shot promoting: provide successful examples of a task and then ask the model to perform a similar task. \n",
    "- Chain of thought reasoning: request a series of reasoning steps in prompts to help the model achieve correct answers\n",
    "- Chain of prompts: split a task into multiple prompts where each prompt can focus on a sub-task at a time and take different actions at different stages. It saves tokens, is easier to test, can involve human input, or use external tools.\n",
    "- Interactive process \n",
    "  1. Try something first \n",
    "  2. Analyses the result, identify errors, and redefine the prompt \n",
    "  3. Test the prompts with different datasets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972159e-3c51-4d95-8fd0-7e85bb572821",
   "metadata": {},
   "source": [
    "An example using delimiters, structured output and few-shot promoting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d9da0-de00-4611-b448-71433d6700f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '###'\n",
    "sentence1 = 'I love cat.'\n",
    "sentence2 = 'I love dog.'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"analyze the sentiment in a sentence delimitered by {delimiter},\n",
    "                                     return the result as a JSON document\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence1}{delimiter}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{sentiment:positive}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence2}{delimiter}\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adfdc4-2bea-476d-9c0b-6ee8bff24436",
   "metadata": {},
   "source": [
    "## Analyze Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbef7a-54ba-4a6e-a5a5-a050cd887a70",
   "metadata": {},
   "source": [
    "### Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac135f-43ea-4499-9aac-224324b9e727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n",
    "\n",
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection\n",
    "tweet_collection.create_index([(\"tweet.id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcfa9f-34a3-4902-b3ac-52b56cfb890d",
   "metadata": {},
   "source": [
    "### Extract Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2d39e-603b-4d41-9a23-b4db8dcdad2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter={\n",
    "\n",
    "    \n",
    "}\n",
    "project={\n",
    "    'tweet.text': 1, \n",
    "    'tweet.id': 1\n",
    "}\n",
    "#rename the client to mongo_client\n",
    "result = mongo_client['demo']['tweet_collection'].find(\n",
    "  filter=filter,\n",
    "  projection=project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4082df-a6f5-4427-b059-90995c1b5571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for tweet in result:\n",
    "    tweet_data.append(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0713c-4ebb-4cc0-b3e5-e307f9b40a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of tweets: ',len(tweet_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d566a4-aafc-4592-ab05-33af9f88e220",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarization \n",
    "- Analyze election tweets with delimiters \n",
    "- Change the size of the summarization \n",
    "- Summarize tweets and focus on different perspectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548343d-ce9b-4960-88c2-d9586631a6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd324d10-eb50-4d2b-a9ac-56af268d37a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    limit the summary to 20 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09adab-a49c-453f-af26-3ecc4edd7603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    focus on how people discuss AI,\n",
    "                                    limit the summary to 50 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c75ab-00d8-44e2-a63e-b4b3aa1847e1",
   "metadata": {},
   "source": [
    "### Moderation \n",
    "- Iterate each tweet and use the [moeration endpoint](https://platform.openai.com/docs/api-reference/moderations) to identify flagged tweets\n",
    "- Print flagged tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3eee06-540d-4126-945c-8153165d88b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flag_help(tweet):\n",
    "    response = client.moderations.create(\n",
    "        model=\"omni-moderation-latest\",\n",
    "        input=tweet)\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        print('===')\n",
    "        cat_dict = response.results[0].categories.to_dict()\n",
    "        for cat in cat_dict.keys():\n",
    "            if cat_dict.get(cat):\n",
    "                print (cat)\n",
    "                print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6878285-cd9f-4878-8cc1-cee9bbd8160c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    flag_help(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7a7d3-9097-4f70-a7f3-7ba23643e60a",
   "metadata": {},
   "source": [
    "### Transforming\n",
    "- Translating to a different language \n",
    "- Transform tones, such as formal vs. informal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee398dde-df13-4911-bbbf-8151c49ace98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"translate the tweets delimited by {delimiter} into Chinese\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b2219-b1f9-4be8-9d7c-2f1daa733e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"rewrite the tweets delimited by {delimiter} in the tone like Stewie \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bbb3a-f1c9-4f1b-9f0f-c9d783f6bb1f",
   "metadata": {},
   "source": [
    "### Inferring\n",
    "- Use step-by-step instructions with delimiters to:\n",
    "  1. Identify sentiments\n",
    "  2. Identify emotions\n",
    "  3. Extract mentioned people's names\n",
    "  3. Identify whether a tweet supports Democratic, Republican, or unknown \n",
    "  4. Extract outputs into a structured JSON document. \n",
    "- Identify topics from Tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5211-eef0-4f24-b8ca-116f9e303675",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a single word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4fb96-a33c-44a0-b754-58efc2972c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} to identify 10 topics, \n",
    "                                  Do not wrap the json codes in JSON markers \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter} \"}]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c9e00-9cbb-4f96-a0bf-79135d0c8262",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expanding with multiple prompts \n",
    "- Identify which party receives majority supports\n",
    "- Provide contexts in the system message\n",
    "- Create a chatbot to answer users’ inquiry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f68d6-2794-452f-9d5a-4b52fac427d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_result = []\n",
    "from tqdm import tqdm\n",
    "for tweet in tqdm(tweet_data):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a singple word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    analysis_result.append(openai_help(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564426c-53a9-4415-9d94-790ea68907de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601722e-7f37-45fb-b580-9aeed74fe3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet analysis reuslt delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} count the number of tweets that support Democratic and Republican;\n",
    "                                        step 2 {delimiter} identify the common sentiments and emotoions to each mentioned people;\n",
    "                                        step 3 {delimiter} organize the result in a json document with keys <Democratic count>, <Republican count>, <people name>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{analysis_result}{delimiter} \"}]\n",
    "analysis_summary = openai_help(messages)\n",
    "print(analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f98ac-b2f6-4741-82c9-8e8f88f09cf1",
   "metadata": {},
   "source": [
    "## Create a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91173534-53b8-4d6b-b9c0-198913b7ada8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [\n",
    "\n",
    "{\"role\": \"system\", \"content\": f\"\"\"you are a chabot answer user questions based on the tweets,\n",
    "                                {delimiter}{tweet_data}{delimiter}, \n",
    "                                if user mentioned a people name in the {delimiter}{analysis_summary}{delimiter} people field,report the corresponding sentiment and emotion,\n",
    "                            \n",
    "                            \"\"\"}\n",
    "]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a949601-5af9-4d0b-80d7-5297cc4e52f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f497dd9-8e6e-4f40-b546-8fe225185729",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Isa Fulford and Andrew Ng. n.d.-a. *“Building Systems with the ChatGPT API.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/.\n",
    "- ———. n.d.-b. *“ChatGPT Prompt Engineering for Developers.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/.\n",
    "- OpenAI. n.d. *“OpenAI Documents.”* OpenAI. Accessed October 18, 2024. https://platform.openai.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06a39-30aa-498b-aff2-049fd65b7fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
