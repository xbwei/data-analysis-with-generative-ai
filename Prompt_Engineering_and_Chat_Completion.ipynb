{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119a978c-794a-42a7-8926-cda6871c8613",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Chat Completion\n",
    "This is a simple tutorial that teaches prompt engineering basics and analyzes Twitter data using OpenAI large language models (LLMs).\n",
    "Please purchase an [OpenAI API](https://openai.com/index/openai-api/) and store it securely. This tutorial uses [AWS Secrets Manager](https://aws.amazon.com/secrets-manager/) to store the API keys.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15700978-787e-407e-a940-c977a71b3044",
   "metadata": {},
   "source": [
    "## Large Language Model Basics\n",
    "LLMs predict the next world using supervised learning. To predict the following sentence: \n",
    "\n",
    "`Learning data science in the cloud with AI`\n",
    "\n",
    "A model needs to learn to predict the following steps:\n",
    "\n",
    "|Input|Output|\n",
    "|:---|---|\n",
    "|Learning data science |in |\n",
    "|Learning data science in |the | \n",
    "|Learning data science in the |cloud |\n",
    "|Learning data science in the cloud |with |\n",
    "|Learning data science in the cloud with |AI|\n",
    "\n",
    "To train an LLM model:\n",
    "1. Training a base LLM model on a large amount of training data to predict the next word \n",
    "2. Fine-tune on examples where outputs follow instructions in the input \n",
    "3. Human rates the quality of different LLM outputs \n",
    "4. Tune LLM to generate outputs with higher rates using RLHF (Reinforcement learning from human feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726290-4f69-4f9f-94d4-18b9c8f26f14",
   "metadata": {},
   "source": [
    "## Set up OpenAI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9019645-db86-4235-93e7-cbd52e770afc",
   "metadata": {},
   "source": [
    "Load the API keys with AWS Secrets Manage Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f6d31-1f82-47e5-9fa4-de3da8aa068a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92790e72-aea1-4acc-b98d-a6782550777c",
   "metadata": {},
   "source": [
    "## Install Python libraries.\n",
    "\n",
    "- openai: call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4f923-3b7c-4bd2-945a-1fbda250e8df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276093f1-824b-4793-bb59-dc30c7d84fb4",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and define a `openai_help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126647a-fbda-42c3-bebb-d689802c6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Image, Markdown\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "def openai_help(messages, model=model, temperature =temperature ):\n",
    "    messages = messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bc14c-2609-4c3e-aa5d-762cd3d06ac0",
   "metadata": {},
   "source": [
    "Temperature: \n",
    "- Low temperature: always choose the most likely response, reliable, predictable responses  \n",
    "- High temperature: diverse responses, more creative responses\n",
    "\n",
    "Tokens and Models: \n",
    "- LLM predicts tokens, which are commonly occurring sequences of characters. \n",
    "- One token is about four characters in English, and 100 tokens are roughly 75 words. Check [token estimate](https://platform.openai.com/tokenizer).\n",
    "- Different models can process various amounts of tokens at different performance levels and costs. Check [OpenAI models](https://platform.openai.com/docs/models) for more details.\n",
    "\n",
    "Roles:\n",
    "- system: specify the overall tone or behavior of the assistant \n",
    "- user: instruction given to the LLM\n",
    "- assistant: LLM responded content, we also can provide content in few-shot promoting or histories of conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef378-e825-40ca-a565-371ba96268a1",
   "metadata": {},
   "source": [
    "A simple example using [gtp-4o](https://platform.openai.com/docs/models/gpt-4o) and temperature 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b746d9-f11f-4f46-96f5-64dd40f6dc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of USA\"}]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcbc19-1ea0-456a-ba84-8f76ef87ba30",
   "metadata": {},
   "source": [
    "Add a system message asking LLM to act as a high school teacher with different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608f8d0-fefb-41a7-8713-1287b3cd7047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"use tone as a middle school teacher\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of USA\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages, temperature = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887fc65-5f97-4530-b81b-f158ea2af413",
   "metadata": {},
   "source": [
    "Add assistant messages to teach LLM what `##` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37e101-f820-4ba7-969c-ce05b53aafe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 1##1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 11\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2##2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 22\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 3##3\"},\n",
    "    ]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addef986-2e0c-4849-bc7a-48b102fbf2fe",
   "metadata": {},
   "source": [
    "## Prompt Engineering Principles \n",
    "- Use delimiters to separate different parts of a prompt to provide clear instructions and prevent prompt injections.\n",
    "- Structure outputs in JSON documents or other formats to use the outputs in subsequent steps \n",
    "- Few-shot promoting: provide successful examples of a task and then ask the model to perform a similar task. \n",
    "- Chain of thought reasoning: request a series of reasoning steps in prompts to help the model achieve correct answers\n",
    "- Chain of prompts: split a task into multiple prompts where each prompt can focus on a sub-task at a time and take different actions at different stages. It saves tokens, is easier to test, can involve human input, or use external tools.\n",
    "- Interactive process \n",
    "  1. Try something first \n",
    "  2. Analyses the result, identify errors, and redefine the prompt \n",
    "  3. Test the prompts with different datasets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972159e-3c51-4d95-8fd0-7e85bb572821",
   "metadata": {},
   "source": [
    "An example using delimiters, structured output and few-shot promoting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d9da0-de00-4611-b448-71433d6700f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '###'\n",
    "sentence1 = 'I love cat.'\n",
    "sentence2 = 'I love dog.'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"analyze the sentiment in a sentence delimitered by {delimiter},\n",
    "                                     return the result as a JSON document\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence1}{delimiter}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{sentiment:positive}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence2}{delimiter}\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adfdc4-2bea-476d-9c0b-6ee8bff24436",
   "metadata": {},
   "source": [
    "## Analyze Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4082df-a6f5-4427-b059-90995c1b5571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tweet_text.json', 'r', encoding='utf-8') as f:\n",
    "    tweet_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0713c-4ebb-4cc0-b3e5-e307f9b40a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of tweets:\", len(tweet_data))\n",
    "print(\"Sample tweet:\", tweet_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d566a4-aafc-4592-ab05-33af9f88e220",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarization \n",
    "- Analyze tweets with delimiters \n",
    "- Change the size of the summarization \n",
    "- Summarize tweets and focus on different perspectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548343d-ce9b-4960-88c2-d9586631a6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a summary of the tweets delimited by {delimiter}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "display(Markdown(openai_help(messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd324d10-eb50-4d2b-a9ac-56af268d37a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a summary of the tweets delimited by {delimiter},\n",
    "                                    limit the summary to 20 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "display(Markdown(openai_help(messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09adab-a49c-453f-af26-3ecc4edd7603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    focus on how people learn AI,\n",
    "                                    limit the summary to 50 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "display(Markdown(openai_help(messages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c75ab-00d8-44e2-a63e-b4b3aa1847e1",
   "metadata": {},
   "source": [
    "### Moderation \n",
    "- Iterate each tweet and use the [moeration endpoint](https://platform.openai.com/docs/api-reference/moderations) to identify flagged tweets\n",
    "- Print flagged tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3eee06-540d-4126-945c-8153165d88b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flag_help(tweet):\n",
    "    response = client.moderations.create(\n",
    "        model=\"omni-moderation-latest\",\n",
    "        input=tweet)\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        print('===')\n",
    "        cat_dict = response.results[0].categories.to_dict()\n",
    "        for cat in cat_dict.keys():\n",
    "            if cat_dict.get(cat):\n",
    "                print (cat)\n",
    "                print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6878285-cd9f-4878-8cc1-cee9bbd8160c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data:\n",
    "    # print(tweet['tweet']['text'])\n",
    "    flag_help(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7a7d3-9097-4f70-a7f3-7ba23643e60a",
   "metadata": {},
   "source": [
    "### Transforming\n",
    "- Translating to a different language \n",
    "- Transform tones, such as formal vs. informal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee398dde-df13-4911-bbbf-8151c49ace98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data[:10]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"translate the tweets delimited by {delimiter} into Chinese\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet['tweet']['text']}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b2219-b1f9-4be8-9d7c-2f1daa733e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data[:10]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"rewrite the tweets delimited by {delimiter} in the tone like Stewie \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet['tweet']['text']}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bbb3a-f1c9-4f1b-9f0f-c9d783f6bb1f",
   "metadata": {},
   "source": [
    "### Inferring\n",
    "- Use step-by-step instructions with delimiters to:\n",
    "  1. Identify sentiments\n",
    "  2. Identify emotions\n",
    "  3. Extract the mentioned people's or organization's names\n",
    "  4. Extract outputs into a structured JSON document. \n",
    "- Identify topics from Tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5211-eef0-4f24-b8ca-116f9e303675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_data[:10]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned people or organizations;\n",
    "                                        step 4 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet['tweet']['text']}{delimiter} \"}]\n",
    "    print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4fb96-a33c-44a0-b754-58efc2972c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} to identify 10 topics, \n",
    "                                  Do not wrap the json codes in JSON markers \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter} \"}]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c9e00-9cbb-4f96-a0bf-79135d0c8262",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expanding with multiple prompts \n",
    "- Identify topics\n",
    "- Provide contexts in the system message\n",
    "- Create a chatbot to answer users‚Äô inquiry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f68d6-2794-452f-9d5a-4b52fac427d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_result = []\n",
    "from tqdm import tqdm\n",
    "for tweet in tqdm(tweet_data):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative, or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned people or organizations;\n",
    "                                        step 4 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    analysis_result.append(openai_help(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564426c-53a9-4415-9d94-790ea68907de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601722e-7f37-45fb-b580-9aeed74fe3a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet analysis result delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} count the number of tweets mentioned by people or organizations;\n",
    "                                        step 2 {delimiter} identify the common sentiments and emotions for each mentioned person or organization;\n",
    "                                        step 3 {delimiter} Organize the result in a json document with keys <people or organization name> \n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{analysis_result}{delimiter} \"}]\n",
    "analysis_summary = openai_help(messages)\n",
    "print(analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f98ac-b2f6-4741-82c9-8e8f88f09cf1",
   "metadata": {},
   "source": [
    "## Create a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91173534-53b8-4d6b-b9c0-198913b7ada8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [\n",
    "\n",
    "{\"role\": \"system\", \"content\": f\"\"\"you are a chatbot that answers user questions based on the tweets,\n",
    "                                {delimiter}{tweet_data}{delimiter}, \n",
    "                                if user mentioned a people or organization name in the {delimiter}{analysis_summary}{delimiter}, report the corresponding sentiment and emotion\n",
    "                            \n",
    "                            \"\"\"}\n",
    "]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a949601-5af9-4d0b-80d7-5297cc4e52f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    display(Markdown(f\"Chatbot: {reply}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b591d-c25e-4801-bd13-f00a01725133",
   "metadata": {},
   "source": [
    "## üß† Try It Yourself: Prompt Engineering Practice\n",
    "üëâ Be sure to **run your own cells** and show the outputs before uploading the notebook to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcad5cb-14a3-4a45-af9b-ce6fe46cf95f",
   "metadata": {},
   "source": [
    "1. **Summarize your tweets differently**  \n",
    "   Change your system message to summarize tweets from a new perspective ‚Äî  \n",
    "   for example:  \n",
    "   *‚ÄúSummarize what people say about AI in education.‚Äù*  \n",
    "   or  \n",
    "   *‚ÄúSummarize how people feel about the election.‚Äù*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540a7ae-2993-4621-8bc2-f345a9b0d1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "972b80b7-046c-4db9-bf3b-8bdbf9af972d",
   "metadata": {},
   "source": [
    "2. **Translate tweets**  \n",
    "   Write a prompt that translates 10 tweets into another language,  \n",
    "   such as Chinese, Spanish, or French.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31860504-f323-4e8f-a18c-1ba0c73a67ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612f693e-35a3-45eb-a7ba-4406566e5633",
   "metadata": {},
   "source": [
    "3. **Simplify or rewrite tweets**  \n",
    "   Ask the model to rewrite 10 tweets in a more polite, formal, or funny tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4cb33-dd5d-421c-a41f-8dbf7fc5c049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a99ec0c0-5341-4f25-8571-77ec49d5fd1f",
   "metadata": {},
   "source": [
    "4. **Find keywords**  \n",
    "   Design a prompt that extracts the top five most common keywords  \n",
    "   from your tweet text and returns them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f99c7-2c21-4fc9-ae37-cd970b5c92b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1da8e-82b0-4c18-9dc2-a2d699ab8582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f497dd9-8e6e-4f40-b546-8fe225185729",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Isa Fulford and Andrew Ng. n.d.-a. *‚ÄúBuilding Systems with the ChatGPT API.‚Äù* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/.\n",
    "- ‚Äî‚Äî‚Äî. n.d.-b. *‚ÄúChatGPT Prompt Engineering for Developers.‚Äù* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/.\n",
    "- OpenAI. n.d. *‚ÄúOpenAI Documents.‚Äù* OpenAI. Accessed October 18, 2024. https://platform.openai.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06a39-30aa-498b-aff2-049fd65b7fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
