{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f7f8f4-d37f-4886-ad2f-9a1d9661bd1b",
   "metadata": {},
   "source": [
    "# Analyzing Data and Interpreting Images with OpenAI's o1 Reasoning Model vs. GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a830d-95fd-4bb0-8156-f4ce5ee41f95",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "OpenAI's o1 reasoning model is designed for complex problem-solving, data analysis, and image interpretation by simulating a multi-step thought process before generating responses. Unlike traditional GPT models, which produce output in a single pass, reasoning models use internal **reasoning tokens** to explore multiple approaches before finalizing an answer.\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://cdn.openai.com/API/images/guides/reasoning_tokens.png\" alt=\"Reasoning Tokens\" width=\"600\">\n",
    "</p>  \n",
    "\n",
    "*Source: [OpenAI Reasoning Models Guide](https://platform.openai.com/docs/guides/reasoning)*\n",
    "\n",
    "**Key Differences: o1 Reasoning Model vs. GPT**\n",
    "- Multi-step reasoning: o1 evaluates different solutions before selecting the best response.\n",
    "- Deeper analytical capabilities: Optimized for complex data interpretation tasks.\n",
    "- Context-aware image analysis: Provides more structured and insightful image descriptions.\n",
    "- Reasoning Effort Control: Users can adjust the depth of reasoning (`low`, `medium`, `high`).\n",
    "\n",
    "\n",
    "For more details, refer to the [OpenAI Reasoning Models Guide](https://platform.openai.com/docs/guides/reasoning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa19529-a6a5-486b-802e-ddfb39fb85f1",
   "metadata": {},
   "source": [
    "## Purchase and Store API Key\n",
    "\n",
    "You need to **purchase** your [OpenAI](https://openai.com/) API key and store it securely, such as in **AWS Secrets Manager**.\n",
    "\n",
    "- **Key Name:** `api_key`  \n",
    "- **Key Value:** `<your OpenAI API key>`  \n",
    "- **Secret Name:** `openai`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a126d9e-1487-4905-8cc0-5d55d1a06594",
   "metadata": {},
   "source": [
    "## Install Python Libraries\n",
    "\n",
    "- **openai**: Used to call `o1` and `GPT` models for data analysis and image interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05dcb1-dab0-4a06-bf2b-c695a8d19d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca255da8-7177-49e6-bff7-27501305b4f6",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "The following libraries are used in this notebook:\n",
    "\n",
    "- **boto3**: AWS SDK for Python, used to interact with AWS services.\n",
    "- **json**: Standard Python library for handling JSON data.\n",
    "- **IPython.display**: Provides tools to display images, Markdown content, and other rich media in Jupyter Notebook.\n",
    "- **openai**: Used to call `o1` and `GPT` models for data analysis and image interpretation.\n",
    "- **pandas**: A powerful library for data manipulation and analysis.\n",
    "- **pprint**: Pretty prints data structures for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0d630-749f-484e-8d01-79ec39e0e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from IPython.display import display, Image, Markdown\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd547f9-8c03-4673-a194-e71e01b38a3d",
   "metadata": {},
   "source": [
    "## Retrieve API Keys Securely from AWS Secrets Manager\n",
    "\n",
    "The following function, `get_secret()`, retrieves a secret from **AWS Secrets Manager**. This is a secure way to store and access sensitive credentials, such as API keys, without hardcoding them into the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3f543-0716-483c-88ce-b41f5fb418cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5711939-503e-44f6-bb28-0671c1131e26",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client\n",
    "\n",
    "The following code initializes the OpenAI client using a securely stored API key retrieved from AWS Secrets Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921be4e1-921f-4c84-b68d-fc72b435cc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= get_secret('openai')['api_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860098d7-cfcc-4791-9b42-c526f8ff620a",
   "metadata": {},
   "source": [
    "## Load and Analyze the Diamonds Dataset\n",
    "\n",
    "This notebook uses the **diamonds dataset ([diamonds.csv](https://github.com/lbsocial/data-analysis-with-generative-ai/blob/main/diamonds.csv))**, which contains detailed attributes of diamonds, including weight, color, clarity, and price.\n",
    "\n",
    "One interesting pattern in the dataset is that **diamonds with \"IF\" (Internally Flawless) clarity tend to have the lowest average price** compared to other clarity grades. This observation is counterintuitive, as one might expect the highest-clarity diamonds to be the most expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef8c09-e485-4bea-b86b-275cce615b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diamonds.csv')\n",
    "data_json = df.to_json(orient=\"records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df8274-f532-4103-9b8a-a882aa23eb86",
   "metadata": {},
   "source": [
    "## Generate Data Analysis Prompt for OpenAI Model\n",
    "\n",
    "To investigate why diamonds with **IF (Internally Flawless) clarity** have the **lowest average price**, we generate a structured prompt for the OpenAI model. The model will analyze the dataset and generate insights, including **Python code for visualizations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7ac96-aef2-425c-91ae-6b004a3ccce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prompt = f\"Analyze the provided data and determine why diamonds with IF clarity have the lowest average price. Provide Python-generated charts to support your conclusion. Data: {data_json}\"\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e269bba-2c1a-47e9-9662-3542873fa8ce",
   "metadata": {},
   "source": [
    "## Define a Function to Get Assistance from OpenAI GPT-4o\n",
    "\n",
    "The following function, `openai_gpt_help()`, sends a prompt to OpenAI's **GPT-4o model** and returns a response. It also prints the number of tokens used in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02a837-a5c0-409e-92ce-7ae93e58c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_gpt_help(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        temperature = 0\n",
    "    )\n",
    "    token_usage = response.usage\n",
    "    \n",
    "    pprint(f\"Tokens used: {token_usage}\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df292b10-8857-4902-b2e4-8dab5602d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_result = openai_gpt_help(prompt=data_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360e35d-3dda-4447-8b5e-f58d16ad91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(gpt_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068efcc-c82a-40d8-8d5b-3939f2417a4e",
   "metadata": {},
   "source": [
    "## Define a Function to Get Assistance from OpenAI o1 Model  \n",
    "\n",
    "The following function, `openai_o_help()`, sends a prompt to OpenAI's **o1 reasoning model** and returns a response.  \n",
    "\n",
    "### Key Differences Between o1 and GPT Models:\n",
    "- **Reasoning Effort**: The o1 model allows users to control reasoning depth using `reasoning_effort` (`low`, `medium`, `high`).  \n",
    "- **No Temperature Parameter**: Unlike GPT models, **o1 does not support `temperature`**.  \n",
    "- **Developer Messages Replace System Messages**:  \n",
    "  - Starting with `o1-2024-12-17`, **developer messages** replace **system messages** to align with chain-of-command behavior.  \n",
    "\n",
    "### Best Practices for Prompting o1  \n",
    "- **Keep prompts simple and direct.**  \n",
    "- **Avoid chain-of-thought prompts.** o1 reasons internally, so step-by-step instructions aren't needed.  \n",
    "- **Use delimiters for clarity.** Use Markdown, XML tags, or section titles.  \n",
    "- **Try zero-shot first.** If needed, add few-shot examples that closely match your goal.  \n",
    "- **Be explicit.** Clearly define success criteria and constraints.  \n",
    "- **Markdown is disabled by default.** To enable, start with `\"Formatting re-enabled\"`.  \n",
    "\n",
    "Source: [OpenAI Reasoning Models Best Practices Guide](https://platform.openai.com/docs/guides/reasoning-best-practices).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3d84b-b101-4299-b01a-ee4285c7608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_o_help(prompt):\n",
    "    messages = [ {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model='o1',\n",
    "        reasoning_effort=\"high\", # low, medium or high\n",
    "        messages=messages,\n",
    "\n",
    "    )\n",
    "    token_usage = response.usage\n",
    "    \n",
    "    pprint(f\"Tokens used: {token_usage}\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc9ef3-4510-4faf-995f-31a58134b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_result = openai_o_help(prompt=data_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab95a7-ee31-49c7-b2ad-f77996be5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0251d-1b9f-41ec-90b4-c95dc865971d",
   "metadata": {},
   "source": [
    "## Load and Display an Image from a URL\n",
    "\n",
    "This code retrieves an image from a specified URL and displays it using the **PIL (Pillow) library**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55475ed3-201f-420c-9903-f80667d14490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "image_url = \"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*VPRpf0YnchAwN0mjeAz4pA.jpeg\"\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be1131-1a04-4e7a-a2cb-1fbee74ae817",
   "metadata": {},
   "source": [
    "## Create an Image Analysis Prompt\n",
    "\n",
    "The following code constructs a **structured prompt** for analyzing an image. It sends both **text input** and an **image URL** to an AI model for interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4906e-85e1-44d8-b789-d502224f0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prompt = [\n",
    "                    {\"type\": \"text\", \"text\": 'what is wrong with this image?'},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\n",
    "                        \"url\": image_url}\n",
    "                    }\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67246b5-cd12-4195-91a3-5b970bd5a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_result = openai_gpt_help(prompt=image_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eed42-879d-4c11-9eb6-d104db8cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(gpt_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c18ebd-828d-4ca0-b7aa-471ff519dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_result = openai_o_help(prompt=image_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492052c-4084-4d7d-af27-ab3cd503ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(o1_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392719c-faa6-4438-a5ea-5e8e6d613d90",
   "metadata": {},
   "source": [
    "## References  \n",
    "- **OpenAI Reasoning Models Guide**: [OpenAI](https://platform.openai.com/docs/guides/reasoning)  \n",
    "- **OpenAI Reasoning Models Best Practices Guide**: [OpenAI](https://platform.openai.com/docs/guides/reasoning-best-practices)  \n",
    "- **Colin Jarvis. “Reasoning with O1.” DeepLearning.AI.** Accessed February 14, 2025. [DeepLearning.AI](https://www.deeplearning.ai/short-courses/reasoning-with-o1/)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
